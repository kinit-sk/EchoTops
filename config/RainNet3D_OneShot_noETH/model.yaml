# configurations for MFUNET model

# Parameters for training model
train_params:
  device: cuda:0
  #device: cpu
  train_batch_size: 16
  valid_batch_size: 16
  test_batch_size: 16
  predict_batch_size: 16
  max_epochs: 9999
  # Max time used for training (days:hours:mins:secs)
  max_time: "00:47:30:00"
  # Validate after every n batches
  val_check_interval: 1.0
  num_workers: 0
  gpus: 1
  savefile: "Delft-ETH-May"
  # many leadtimes
  verif_leadtimes: 18
  # number of batches to validate on
  val_batches: 9999999
  # number of baches to train on (per epoch)
  train_batches: 9999999
  early_stopping:
    strict: false
    verbose: true
    monitor: "val_loss"
    patience: 5
  lr_scheduler:
    verbose: true
    name: "reduce_lr_on_plateau"
    kwargs:
      mode: "min"
      factor: 0.8
      patience: 0

model:
  lr: 1e-04
  rainnet:
    output_shape: [1, 18, 336, 272]
    kernel_size: 3
    mode: "regression"
    conv_shape:
      [
        ["1", [1, 64]],
        ["2", [64, 128]],
        ["3", [128, 256]],
        ["4", [256, 512]],
        ["5", [512, 1024]],
        ["6", [1536, 512]],
        ["7", [768, 256]],
        ["8", [384, 128]],
        ["9", [192, 64]],
      ]

  loss:
    name: "mse"
    precip_only: true
  train_leadtimes: 18
prediction:
  predict_leadtimes: 18
prediction_output:
  # Output directory
  output_dir: /scratch/p709-24-2/outputs/nETH/
  group_format: "{common_time:%Y-%m-%d %H:%M:%S}/model"
  # Attributes of the dataset in the HDF5 file
  what_attrs:
    quantity: DBZH
    gain: 0.5
    offset: -32
    nodata: 255
    undetect: 0